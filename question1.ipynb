{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TL;DR: <br>\n",
    "Q1.a)<br>\n",
    "At first glance, I imagine that some high-end outliers in our dataset are skewing the AOV.<br>\n",
    "Q1.b)<br>\n",
    "In that case the mean should work a lot better for us in approximating AOV.<br>\n",
    "Q1.c)<br>\n",
    "The mean order amount is 284.00<br>\n",
    "<br>\n",
    "Read more below on how I would go about investigating the validity of my hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1a: *Think about what could be going wrong with our calculation. Think about a better way to evaluate this data*\n",
    "\n",
    "Immediately, I think the average of `3145.13` is being skewed either a number of very large orders or by one shop that does very high volumes orders consistently. I would check the standard deviation to confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_info    = pd.read_csv(\"data_sneakers.csv\")\n",
    "volume_info = all_info[['order_amount', 'total_items']]\n",
    "\n",
    "# Show a general analysis of the order_amount and total_items columns, including percentiles in 10% increments.\n",
    "volume_info.describe(percentiles=[x/10.0 for x in range(0,10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `describe()` outputs shows us the rather extreme standard deviation of `41282.5`. And there we see our `3145.13` number, it's the mean order amount. These percentiles don't tell us much so let's look a little closer at the upper range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_info.describe(percentiles=[x/100.0 for x in range(90,100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! We've found the outliers! All the way up in the 99th percentile it looks like we've got a couple points up near that `70400` max value. Let's play around with some other numbers to see how many outliers we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_amounts = volume_info['order_amount']\n",
    "\n",
    "search_threshold = order_amounts.max() - order_amounts.std()\n",
    "outliers = order_amounts[ order_amounts >= search_threshold]\n",
    "print(f\"{len(outliers)}/{len(order_amounts)} entries found that exceed {search_threshold} in order_amounts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering AOV these datapoints aren't very useful for us since it gives us a bad indication of what the average customers order value is going to look like. Let's trim these outliers out of our calculation using an Interquartile range\n",
    "(IQR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IQR_calc(data, group_by, factor=1.5, bottom=0.25, top=0.75):\n",
    "    Q1, Q3 = data[group_by].quantile([bottom, top])\n",
    "    IQR = Q3-Q1\n",
    "    min_threshold = Q1 - (1.5 * IQR)\n",
    "    max_threshold = Q3 + (1.5 * IQR)\n",
    "    mask = (data[group_by]>=min_threshold) & (data[group_by]<=max_threshold)\n",
    "    trimmed_data = data.loc[mask]\n",
    "    return trimmed_data\n",
    "\n",
    "# We can be pretty extreme with our IQR here, normally Q1 and Q3\n",
    "# would be further from the edge of our dataset.\n",
    "trimmed_volume_info = IQR_calc(volume_info, 'order_amount', bottom=0.10, top=0.90)\n",
    "trimmed_volume_info.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1b: *What metric would you report for this dataset?*\n",
    "Looks like there is a small percentage of outliers skewing our mean. A median should be good enough to give us a quick look at what a good AOV would look like, since only about the 99th percentile of the data is at the upper extreme, and there don't seem to be many lower extremes either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MEANS:\")\n",
    "print(volume_info.mean())\n",
    "print(trimmed_volume_info.mean())\n",
    "print(\"MEDIANS:\")\n",
    "print(volume_info.median())\n",
    "print(trimmed_volume_info.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1c: *What is its value?*\n",
    "Reporting a median with the data trimmed by our IQR function doesn't even changes the results. So for this case, the median of `284.00` works really quite well. \n",
    "\n",
    "But if we want to stick to the strict definition of AOV a value of `301.84` for our AOV based on the trimmed data from our IQR_calc() function feels acceptable."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
